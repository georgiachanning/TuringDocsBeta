<!DOCTYPE html><HTML><head><script charset="utf-8" src="../../../../assets/__default/flexsearch.bundle.js" type="text/javascript"></script><script charset="utf-8" src="../../../../assets/__default/flexsearch_integration.js" type="text/javascript"></script><meta charset="utf-8"/><meta content="IE=edge" http-equiv="X-UA-Compatible"/><meta content="en" http-equiv="content-language"/><meta content="width=device-width, initial-scale=1" name="viewport"/><title>Bayesian Multinomial Logistic Regression</title><meta content="Bayesian Multinomial Logistic RegressionMultinomial logistic regression is an extension of logistic regression. Logistic regression is used to model problems..." name="description"/><meta content="The Turing Team" name="author"/><meta content="red" name="theme-color"/><link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/><link href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono" rel="stylesheet"/><style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style><link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet"/><link href="/v0.14.0/tutorials/8-multinomiallogisticregression/" rel="canonical"/><link href="/v0.14.0/feed.xml" rel="alternate" title="Turing.jl" type="application/rss+xml"/><meta content="Copy to clipboard" name="lang:clipboard.copy"/><meta content="Copied to clipboard" name="lang:clipboard.copied"/><meta content="en" name="lang:search.language"/><meta content="True" name="lang:search.pipeline.stopwords"/><meta content="True" name="lang:search.pipeline.trimmer"/><meta content="No matching documents" name="lang:search.result.none"/><meta content="1 matching document" name="lang:search.result.one"/><meta content="# matching documents" name="lang:search.result.other"/><meta content="[\s\-]+" name="lang:search.tokenizer"/><script src="/versions.js"></script><script src="/v0.14.0/assets/js/modernizr.74668098.js"></script><link href="/v0.14.0/assets/img/favicon.ico" rel="shortcut icon"/><link href="/v0.14.0/assets/css/main.css" rel="stylesheet"/><link href="/v0.14.0/assets/css/palette.css" rel="stylesheet"/><link href="/v0.14.0/assets/css/header.css" rel="stylesheet"/><link href="https://stackpath.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet"/><link href="../../../../assets/__default/multidoc.css" rel="stylesheet" type="text/css"/><link href="../../../../assets/__default/flexsearch.css" rel="stylesheet" type="text/css"/></head><body data-md-color-accent="red" data-md-color-primary="red" dir="ltr"><nav id="multi-page-nav"><div class="hidden-on-mobile" id="nav-items"><a class="nav-link active nav-item" href="../../../">Turing</a><a class="nav-link nav-item" href="../../../../ppl/">DynamicPPL</a><a class="nav-link nav-item" href="../../../../hmc/">AdvancedHMC</a><a class="nav-link nav-item" href="../../../../ns/">NestedSamplers</a><a class="nav-link nav-item" href="../../../../mcmcc/">MCMCChains</a><div class="search nav-item"><input id="search-input" placeholder="Search..."/><ul class="suggestions hidden" id="search-result-container"></ul><div class="search-keybinding">/</div></div></div><a id="multidoc-toggler"></a></nav><svg class="md-svg"><defs><svg><path d="M160 304q0 10-3.125 20.5t-10.75 19-18.125 8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19 18.125-8.5 18.125 8.5 10.75 19 3.125 20.5zM320 304q0 10-3.125 20.5t-10.75 19-18.125 8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19 18.125-8.5 18.125 8.5 10.75 19 3.125 20.5zM360 304q0-30-17.25-51t-46.75-21q-10.25 0-48.75 5.25-17.75 2.75-39.25 2.75t-39.25-2.75q-38-5.25-48.75-5.25-29.5 0-46.75 21t-17.25 51q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75 8-38.375zM416 260q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5-41.75 1.125q-19.5 0-35.5-0.75t-36.875-3.125-38.125-7.5-34.25-12.875-30.25-20.25-21.5-28.75q-15.5-30.75-15.5-82.75 0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875q36.75-8.75 77.25-8.75 37 0 70 8 26.25-20.5 46.75-30.25t47.25-9.75q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z" fill="currentColor"></path></svg></defs></svg><input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/><input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/><label class="md-overlay" data-md-component="overlay" for="__drawer"></label><a class="md-skip" href="#bayesian-multinomial-logistic-regression" tabindex="1"> Skip to content </a><header class="md-header" data-md-component="header" data-md-state="none"><nav class="md-header-nav md-grid"><div class="md-flex"><div class="md-flex__cell md-flex__cell--shrink"></div><div class="md-flex__cell md-flex__cell--shrink"><label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label></div><div class="md-flex__cell md-flex__cell--shrink"><a class="md-header-nav__button md-logo" href="/v0.14.0/" title="Turing.jl"><div class="md-flex__ellipsis md-header-nav__title" data-md-component="title"><span class="md-header-nav__topic">Turing.jl</span></div></a></div><div class="md-flex__cell md-flex__cell--shrink"><div class="md-header-nav__source"><div class="dropdown version-switch"><a aria-expanded="false" aria-haspopup="true" class="dropdown-toggle" data-toggle="dropdown" href="#" id="navbarDropdown" role="button"></a><div class="dropdown-menu"></div></div></div></div><div class="md-flex__cell md-flex__cell--shrink"><div class="md-header-nav__source"><a class="md-source" href="/v0.14.0/docs/using-turing/get-started" title="Get started">
                      Get Started
                    </a></div></div><div class="md-flex__cell md-flex__cell--shrink"><div class="md-header-nav__source"><a class="md-source" href="/v0.14.0/docs/using-turing/" title="View documentation">
                        Documentation
                      </a></div></div><div class="md-flex__cell md-flex__cell--shrink"><div class="md-header-nav__source"><a class="md-source" href="/v0.14.0/tutorials/" title="View tutorials">
                          Tutorials
                        </a></div></div><div class="md-flex__cell md-flex__cell--shrink"><div class="md-header-nav__source"><a class="md-source" href="/v0.14.0/news/" title="News">
                          News
                        </a></div></div><div class="md-flex__cell md-flex__cell--shrink"><div class="md-header-nav__source"><a class="md-source" href="/v0.14.0/team/" title="Team">
                          Team
                        </a></div></div><div class="md-flex__cell md-flex__cell--shrink"><div class="md-header-nav__source"><a class="md-source" data-md-source="github" href="https://github.com/TuringLang/Turing.jl" title="Go to repository"><div class="md-source__icon" style="padding-top:5px"><i class="fa fa-github fa-3x"></i></div><div class="md-source__repository">
                      TuringLang/Turing.jl
                    </div></a></div></div><div class="md-flex__cell md-flex__cell--shrink"><div class="md-header-nav__source"><a class="twitter-follow-button" data-show-count="false" data-show-screen-name="false" data-size="large" href="https://twitter.com/TuringLang?ref_src=twsrc%5Etfw">Follow @TuringLang</a><script async="" charset="utf-8" src="https://platform.twitter.com/widgets.js"></script></div></div><div class="md-flex__cell md-flex__cell--shrink"><label class="md-icon md-icon--search md-header-nav__button" for="__search"></label><div class="md-search" data-md-component="search" role="dialog"><label class="md-search__overlay" for="__search"></label><div class="md-search__inner" role="search"><form class="md-search__form" name="search"><input autocapitalize="off" autocomplete="off" autocorrect="off" class="md-search__input" data-md-component="query" data-md-state="active" name="query" placeholder="Search" spellcheck="false" type="text"/><label class="md-icon md-search__icon" for="__search"></label><button class="md-icon md-search__icon" data-md-component="reset" tabindex="-1" type="reset"> Óóç </button></form><div class="md-search__output"><div class="md-search__scrollwrap" data-md-scrollfix=""><div class="md-search-result" data-md-component="result"><div class="md-search-result__meta"> Type to start searching </div><ol class="md-search-result__list"></ol></div></div></div></div></div></div></div></nav></header><div class="md-container"><main class="md-main"><div class="md-main__inner md-grid full-width" data-md-component="container"><div class="md-sidebar md-sidebar--primary" data-md-component="navigation"><div class="md-sidebar__scrollwrap"><div class="md-sidebar__inner"><nav class="md-nav md-nav--primary" data-md-level="0"><label class="md-nav__title md-nav__title--site"><a class="" href="/v0.14.0/" title="Turing.jl"><span class="md-nav__button md-logo">
                Turing.jl
              </span></a></label><ul class="md-nav__list" data-md-scrollfix=""><li class="md-nav__item md-nav__item--active"><input class="md-toggle md-nav__toggle" data-md-toggle="toc" id="__toc" type="checkbox"/><nav class="md-nav md-nav--secondary"><a class="" href="/v0.14.0/" title="Turing.jl"><label class="md-nav__title md-nav__title--site"><span class="md-nav__button md-logo">
                      Turing.jl
                    </span></label></a><div class="md-nav__source"><a class="md-source" data-md-source="github" href="https://github.com/TuringLang/Turing.jl" title="Go to repository"><span class="md-source__icon"><i class="fa fa-github fa-3x"></i></span><span class="md-source__repository">
                      TuringLang/Turing.jl
                    </span></a></div><div class="md-nav__dropdown"><select id="version-selector"></select></div><label class="md-nav__title" for="__drawer"></label><ul class="md-nav__list" data-md-scrollfix=""><li class="md-nav__item md-nav__item--nested navbar_bottom-border"><a class="md-nav__link pancakes-parent-mobile" id="pancakes-using-turing" title="USING TURING">USING TURING</a><nav class="md-nav md-nav--secondary"><a class="md-nav__title mobile-navbar-back" for="__toc">Table of contents</a><ul class="md-nav__list" data-md-scrollfix=""><li class="md-nav__item navbar_bottom-border"><a class="md-nav__link" href="/v0.14.0/docs/using-turing/get-started" id="pancakes-getting-started" title="Getting Started">Getting Started</a></li><li class="md-nav__item navbar_bottom-border"><a class="md-nav__link" href="/v0.14.0/docs/using-turing/quick-start" id="pancakes-quick-start" title="Quick Start">Quick Start</a></li><li class="md-nav__item navbar_bottom-border"><a class="md-nav__link" href="/v0.14.0/docs/using-turing/guide" id="pancakes-guide" title="Guide">Guide</a></li><li class="md-nav__item navbar_bottom-border"><a class="md-nav__link" href="/v0.14.0/docs/using-turing/advanced" id="pancakes-advanced-usage" title="Advanced Usage">Advanced Usage</a></li><li class="md-nav__item navbar_bottom-border"><a class="md-nav__link" href="/v0.14.0/docs/using-turing/autodiff" id="pancakes-automatic-differentiation" title="Automatic Differentiation">Automatic Differentiation</a></li><li class="md-nav__item navbar_bottom-border"><a class="md-nav__link" href="/v0.14.0/docs/using-turing/performancetips" id="pancakes-performance-tips" title="Performance Tips">Performance Tips</a></li><li class="md-nav__item navbar_bottom-border"><a class="md-nav__link" href="/v0.14.0/docs/using-turing/dynamichmc" id="pancakes-using-dynamichmc" title="Using DynamicHMC">Using DynamicHMC</a></li><li class="md-nav__item navbar_bottom-border"><a class="md-nav__link" href="/v0.14.0/docs/using-turing/sampler-viz" id="pancakes-sampler-visualization" title="Sampler Visualization">Sampler Visualization</a></li></ul></nav></li><li class="md-nav__item md-nav__item--nested navbar_bottom-border"><a class="md-nav__link pancakes-parent-mobile" id="pancakes-for-developers" title="FOR DEVELOPERS">FOR DEVELOPERS</a><nav class="md-nav md-nav--secondary"><a class="md-nav__title mobile-navbar-back" for="__toc">Table of contents</a><ul class="md-nav__list" data-md-scrollfix=""><li class="md-nav__item navbar_bottom-border"><a class="md-nav__link" href="/v0.14.0/docs/for-developers/compiler" id="pancakes-turing-compiler-design" title="Turing Compiler Design">Turing Compiler Design</a></li><li class="md-nav__item navbar_bottom-border"><a class="md-nav__link" href="/v0.14.0/docs/for-developers/interface" id="pancakes-interface-guide" title="Interface Guide">Interface Guide</a></li><li class="md-nav__item navbar_bottom-border"><a class="md-nav__link" href="/v0.14.0/docs/for-developers/how_turing_implements_abstractmcmc" id="pancakes-how-turing-implements-abstractmcmc" title="How Turing implements AbstractMCMC">How Turing implements AbstractMCMC</a></li><li class="md-nav__item navbar_bottom-border"><a class="md-nav__link" href="/v0.14.0/docs/for-developers/variational_inference" id="pancakes-variational-inference" title="Variational Inference">Variational Inference</a></li></ul></nav></li><li class="md-nav__item md-nav__item--nested navbar_bottom-border"><a class="md-nav__link pancakes-parent-mobile" id="pancakes-tutorials" title="TUTORIALS">TUTORIALS</a><nav class="md-nav md-nav--secondary"><a class="md-nav__title mobile-navbar-back" for="__toc">Table of contents</a><ul class="md-nav__list" data-md-scrollfix=""><li class="md-nav__item navbar_bottom-border"><a class="md-nav__link" href="/v0.14.0/tutorials" id="pancakes-home" title="Home">Home</a></li><li class="md-nav__item navbar_bottom-border"><a class="md-nav__link" href="/v0.14.0/tutorials/0-introduction" id="pancakes-introduction-to-turing" title="Introduction to Turing">Introduction to Turing</a></li><li class="md-nav__item navbar_bottom-border"><a class="md-nav__link" href="/v0.14.0/tutorials/1-gaussianmixturemodel" id="pancakes-gaussian-mixture-models" title="Gaussian Mixture Models">Gaussian Mixture Models</a></li><li class="md-nav__item navbar_bottom-border"><a class="md-nav__link" href="/v0.14.0/tutorials/2-logisticregression" id="pancakes-bayesian-logistic-regression" title="Bayesian Logistic Regression">Bayesian Logistic Regression</a></li><li class="md-nav__item navbar_bottom-border"><a class="md-nav__link" href="/v0.14.0/tutorials/3-bayesnn" id="pancakes-bayesian-neural-networks" title="Bayesian Neural Networks">Bayesian Neural Networks</a></li><li class="md-nav__item navbar_bottom-border"><a class="md-nav__link" href="/v0.14.0/tutorials/4-bayeshmm" id="pancakes-hidden-markov-models" title="Hidden Markov Models">Hidden Markov Models</a></li><li class="md-nav__item navbar_bottom-border"><a class="md-nav__link" href="/v0.14.0/tutorials/5-linearregression" id="pancakes-linear-regression" title="Linear Regression">Linear Regression</a></li><li class="md-nav__item navbar_bottom-border"><a class="md-nav__link" href="/v0.14.0/tutorials/6-infinitemixturemodel" id="pancakes-infinite-mixture-models" title="Infinite Mixture Models">Infinite Mixture Models</a></li><li class="md-nav__item navbar_bottom-border"><a class="md-nav__link" href="/v0.14.0/tutorials/7-poissonregression" id="pancakes-bayesian-poisson-regression" title="Bayesian Poisson Regression">Bayesian Poisson Regression</a></li><li class="md-nav__item navbar_bottom-border"><a class="md-nav__link" href="/v0.14.0/tutorials/8-multinomiallogisticregression" id="pancakes-multinomial-logistic-regression" title="Multinomial Logistic Regression">Multinomial Logistic Regression</a></li><li class="md-nav__item navbar_bottom-border"><a class="md-nav__link" href="/v0.14.0/tutorials/9-variationalinference" id="pancakes-variational-inference" title="Variational Inference">Variational Inference</a></li><li class="md-nav__item navbar_bottom-border"><a class="md-nav__link" href="/v0.14.0/tutorials/10-bayesiandiffeq" id="pancakes-bayesian-differential-equation" title="Bayesian Differential Equation">Bayesian Differential Equation</a></li></ul></nav></li><li class="md-nav__item md-nav__item--nested navbar_bottom-border"><a class="md-nav__link pancakes-parent-mobile" id="pancakes-api" title="API">API</a><nav class="md-nav md-nav--secondary"><a class="md-nav__title mobile-navbar-back" for="__toc">Table of contents</a><ul class="md-nav__list" data-md-scrollfix=""><li class="md-nav__item navbar_bottom-border"><a class="md-nav__link" href="/v0.14.0/docs/library" id="pancakes-turing" title="Turing">Turing</a></li><li class="md-nav__item navbar_bottom-border"><a class="md-nav__link" href="/v0.14.0/docs/library/advancedhmc/" id="pancakes-advancedhmc" title="AdvancedHMC">AdvancedHMC</a></li><li class="md-nav__item navbar_bottom-border"><a class="md-nav__link" href="/v0.14.0/docs/library/bijectors/" id="pancakes-bijectors" title="Bijectors">Bijectors</a></li></ul></nav></li><li class="md-nav__item md-nav__item--nested navbar_bottom-border"><a class="md-nav__link pancakes-parent-mobile" id="pancakes-contributing" title="CONTRIBUTING">CONTRIBUTING</a><nav class="md-nav md-nav--secondary"><a class="md-nav__title mobile-navbar-back" for="__toc">Table of contents</a><ul class="md-nav__list" data-md-scrollfix=""><li class="md-nav__item navbar_bottom-border"><a class="md-nav__link" href="/v0.14.0/docs/contributing/guide" id="pancakes-how-to-contribute" title="How to Contribute">How to Contribute</a></li><li class="md-nav__item navbar_bottom-border"><a class="md-nav__link" href="/v0.14.0/docs/contributing/style-guide" id="pancakes-style-guide" title="Style Guide">Style Guide</a></li></ul></nav></li></ul></nav></li><li class="md-nav__item mobile-nav" style="display:none"><a class="md-nav__link" title="USING TURING">USING TURING</a></li><li class="md-nav__item mobile-nav" style="display:none"><a class="md-nav__link" title="FOR DEVELOPERS">FOR DEVELOPERS</a></li><li class="md-nav__item mobile-nav" style="display:none"><a class="md-nav__link" title="TUTORIALS">TUTORIALS</a></li><li class="md-nav__item mobile-nav" style="display:none"><a class="md-nav__link" title="API">API</a></li><li class="md-nav__item mobile-nav" style="display:none"><a class="md-nav__link" title="CONTRIBUTING">CONTRIBUTING</a></li><li class="md-nav__item md-nav__item--nested not-mobile-nav invisible"><a class="md-nav__link pancakes-parent " id="pancakes-using-turing" title="USING TURING">USING TURING</a><nav class="md-nav"><ul class="md-nav__list"><li class="md-nav__item"><a class="md-nav__link pancakes-child" href="/v0.14.0/docs/using-turing/get-started" style="display:none;" title="Getting Started">Getting Started</a></li><li class="md-nav__item"><a class="md-nav__link pancakes-child" href="/v0.14.0/docs/using-turing/quick-start" style="display:none;" title="Quick Start">Quick Start</a></li><li class="md-nav__item"><a class="md-nav__link pancakes-child" href="/v0.14.0/docs/using-turing/guide" style="display:none;" title="Guide">Guide</a></li><li class="md-nav__item"><a class="md-nav__link pancakes-child" href="/v0.14.0/docs/using-turing/advanced" style="display:none;" title="Advanced Usage">Advanced Usage</a></li><li class="md-nav__item"><a class="md-nav__link pancakes-child" href="/v0.14.0/docs/using-turing/autodiff" style="display:none;" title="Automatic Differentiation">Automatic Differentiation</a></li><li class="md-nav__item"><a class="md-nav__link pancakes-child" href="/v0.14.0/docs/using-turing/performancetips" style="display:none;" title="Performance Tips">Performance Tips</a></li><li class="md-nav__item"><a class="md-nav__link pancakes-child" href="/v0.14.0/docs/using-turing/dynamichmc" style="display:none;" title="Using DynamicHMC">Using DynamicHMC</a></li><li class="md-nav__item"><a class="md-nav__link pancakes-child" href="/v0.14.0/docs/using-turing/sampler-viz" style="display:none;" title="Sampler Visualization">Sampler Visualization</a></li></ul></nav></li><li class="md-nav__item md-nav__item--nested not-mobile-nav invisible"><a class="md-nav__link pancakes-parent " id="pancakes-for-developers" title="FOR DEVELOPERS">FOR DEVELOPERS</a><nav class="md-nav"><ul class="md-nav__list"><li class="md-nav__item"><a class="md-nav__link pancakes-child" href="/v0.14.0/docs/for-developers/compiler" style="display:none;" title="Turing Compiler Design">Turing Compiler Design</a></li><li class="md-nav__item"><a class="md-nav__link pancakes-child" href="/v0.14.0/docs/for-developers/interface" style="display:none;" title="Interface Guide">Interface Guide</a></li><li class="md-nav__item"><a class="md-nav__link pancakes-child" href="/v0.14.0/docs/for-developers/how_turing_implements_abstractmcmc" style="display:none;" title="How Turing implements AbstractMCMC">How Turing implements AbstractMCMC</a></li><li class="md-nav__item"><a class="md-nav__link pancakes-child" href="/v0.14.0/docs/for-developers/variational_inference" style="display:none;" title="Variational Inference">Variational Inference</a></li></ul></nav></li><li class="md-nav__item md-nav__item--nested not-mobile-nav invisible"><a class="md-nav__link pancakes-parent open-parent" id="pancakes-tutorials" title="TUTORIALS">TUTORIALS</a><nav class="md-nav"><ul class="md-nav__list"><li class="md-nav__item"><a class="md-nav__link pancakes-child" href="/v0.14.0/tutorials" title="Home">Home</a></li><li class="md-nav__item"><a class="md-nav__link pancakes-child" href="/v0.14.0/tutorials/0-introduction" title="Introduction to Turing">Introduction to Turing</a></li><li class="md-nav__item"><a class="md-nav__link pancakes-child" href="/v0.14.0/tutorials/1-gaussianmixturemodel" title="Gaussian Mixture Models">Gaussian Mixture Models</a></li><li class="md-nav__item"><a class="md-nav__link pancakes-child" href="/v0.14.0/tutorials/2-logisticregression" title="Bayesian Logistic Regression">Bayesian Logistic Regression</a></li><li class="md-nav__item"><a class="md-nav__link pancakes-child" href="/v0.14.0/tutorials/3-bayesnn" title="Bayesian Neural Networks">Bayesian Neural Networks</a></li><li class="md-nav__item"><a class="md-nav__link pancakes-child" href="/v0.14.0/tutorials/4-bayeshmm" title="Hidden Markov Models">Hidden Markov Models</a></li><li class="md-nav__item"><a class="md-nav__link pancakes-child" href="/v0.14.0/tutorials/5-linearregression" title="Linear Regression">Linear Regression</a></li><li class="md-nav__item"><a class="md-nav__link pancakes-child" href="/v0.14.0/tutorials/6-infinitemixturemodel" title="Infinite Mixture Models">Infinite Mixture Models</a></li><li class="md-nav__item"><a class="md-nav__link pancakes-child" href="/v0.14.0/tutorials/7-poissonregression" title="Bayesian Poisson Regression">Bayesian Poisson Regression</a></li><li class="md-nav__item"><a class="md-nav__link pancakes-child" href="/v0.14.0/tutorials/8-multinomiallogisticregression" style="color: red;" title="Multinomial Logistic Regression">Multinomial Logistic Regression</a></li><li class="md-nav__item"><a class="md-nav__link pancakes-child" href="/v0.14.0/tutorials/9-variationalinference" title="Variational Inference">Variational Inference</a></li><li class="md-nav__item"><a class="md-nav__link pancakes-child" href="/v0.14.0/tutorials/10-bayesiandiffeq" title="Bayesian Differential Equation">Bayesian Differential Equation</a></li></ul></nav></li><li class="md-nav__item md-nav__item--nested not-mobile-nav invisible"><a class="md-nav__link pancakes-parent " id="pancakes-api" title="API">API</a><nav class="md-nav"><ul class="md-nav__list"><li class="md-nav__item"><a class="md-nav__link pancakes-child" href="/v0.14.0/docs/library" style="display:none;" title="Turing">Turing</a></li><li class="md-nav__item"><a class="md-nav__link pancakes-child" href="/v0.14.0/docs/library/advancedhmc/" style="display:none;" title="AdvancedHMC">AdvancedHMC</a></li><li class="md-nav__item"><a class="md-nav__link pancakes-child" href="/v0.14.0/docs/library/bijectors/" style="display:none;" title="Bijectors">Bijectors</a></li></ul></nav></li><li class="md-nav__item md-nav__item--nested not-mobile-nav invisible"><a class="md-nav__link pancakes-parent " id="pancakes-contributing" title="CONTRIBUTING">CONTRIBUTING</a><nav class="md-nav"><ul class="md-nav__list"><li class="md-nav__item"><a class="md-nav__link pancakes-child" href="/v0.14.0/docs/contributing/guide" style="display:none;" title="How to Contribute">How to Contribute</a></li><li class="md-nav__item"><a class="md-nav__link pancakes-child" href="/v0.14.0/docs/contributing/style-guide" style="display:none;" title="Style Guide">Style Guide</a></li></ul></nav></li></ul></nav></div></div></div><div class="md-sidebar md-sidebar--secondary invisible" data-md-component="toc"><div class="md-sidebar__scrollwrap"><div class="md-sidebar__inner"><nav class="md-nav md-nav--secondary"><label class="md-nav__title" for="__toc">Table of contents</label><ul class="md-nav__list" data-md-scrollfix="" id="nav-toc"></ul><a class="social-link" href="https://twitter.com/intent/tweet?original_referer=https://github.com/TuringLang/Turing.jl/edit/master/docs/src_tutorials/8_MultinomialLogisticRegression.md" title="Tweet this page"><i class="fa fa-twitter fa-1x"></i>Tweet this page</a><a class="social-link" href="https://discourse.julialang.org/c/domain/probprog" title="Ask questions"><i class="fa fa-stack-overflow fa-1x"></i>Ask questions</a><a class="social-link" href="https://github.com/TuringLang/Turing.jl//issues/new?label=question&amp;title=Question:&amp;body=Question%20on:%20https://github.com/TuringLang/Turing.jl/edit/master/docs/_tutorials/8_MultinomialLogisticRegression.md" title="Report issues"><i class="fa fa-comments fa-1x"></i>Report issues</a><a class="social-link" href="https://github.com/TuringLang/Turing.jl/edit/master/docs/src_tutorials/8_MultinomialLogisticRegression.md" title="Edit this page on github"><i class="fa fa-github fa-1x"></i> Edit me</a></nav></div></div></div><div id="md-container-pancakes"><div class="md-content full-width"><article class="md-content__inner md-typeset  full-width"><h1 id="bayesian-multinomial-logistic-regression">Bayesian Multinomial Logistic Regression</h1><p><a href="https://en.wikipedia.org/wiki/Multinomial_logistic_regression">Multinomial logistic regression</a> is an extension of logistic regression. Logistic regression is used to model problems in which there are exactly two possible discrete outcomes. Multinomial logistic regression is used to model problems in which there are two or more possible discrete outcomes.</p><p>In our example, we‚Äôll be using the iris dataset. The goal of the iris multiclass problem is to predict the species of a flower given measurements (in centimeters) of sepal length and width and petal length and width. There are three possible species: Iris setosa, Iris versicolor, and Iris virginica.</p><p>To start, let‚Äôs import all the libraries we‚Äôll need.</p><div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Import Turing and Distributions.</span><span class="k">using</span><span class="n">Turing</span><span class="x">,</span><span class="n">Distributions</span><span class="c"># Import RDatasets.</span><span class="k">using</span><span class="n">RDatasets</span><span class="c"># Import MCMCChains, Plots, and StatsPlots for visualizations and diagnostics.</span><span class="k">using</span><span class="n">MCMCChains</span><span class="x">,</span><span class="n">Plots</span><span class="x">,</span><span class="n">StatsPlots</span><span class="c"># We need a softmax function, which is provided by NNlin.</span><span class="k">using</span><span class="n">NNlib</span><span class="o">:</span><span class="n">softmax</span><span class="c"># Set a seed for reproducibility.</span><span class="k">using</span><span class="n">Random</span><span class="n">Random</span><span class="o">.</span><span class="n">seed!</span><span class="x">(</span><span class="mi">0</span><span class="x">);</span></code></pre></div></div><h2 id="data-cleaning--set-up">Data Cleaning &amp; Set Up</h2><p>Now we‚Äôre going to import our dataset. Twenty rows of the dataset are shown below so you can get a good feel for what kind of data we have.</p><div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Import the "iris" dataset.</span><span class="n">data</span><span class="o">=</span><span class="n">RDatasets</span><span class="o">.</span><span class="n">dataset</span><span class="x">(</span><span class="s">"datasets"</span><span class="x">,</span><span class="s">"iris"</span><span class="x">);</span><span class="c"># Randomly shuffle the rows of the dataset</span><span class="n">num_rows</span><span class="o">=</span><span class="n">size</span><span class="x">(</span><span class="n">data</span><span class="x">,</span><span class="mi">1</span><span class="x">)</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="x">[</span><span class="n">Random</span><span class="o">.</span><span class="n">shuffle</span><span class="x">(</span><span class="mi">1</span><span class="o">:</span><span class="n">num_rows</span><span class="x">),</span><span class="o">:</span><span class="x">]</span><span class="c"># Show twenty rows</span><span class="n">first</span><span class="x">(</span><span class="n">data</span><span class="x">,</span><span class="mi">20</span><span class="x">)</span></code></pre></div></div><p>20 rows √ó 5 columns</p><table class="data-frame"><thead><tr><th></th><th>SepalLength</th><th>SepalWidth</th><th>PetalLength</th><th>PetalWidth</th><th>Species</th></tr><tr><th></th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Categorical‚Ä¶</th></tr></thead><tbody><tr><th>1</th><td>6.9</td><td>3.2</td><td>5.7</td><td>2.3</td><td>virginica</td></tr><tr><th>2</th><td>5.8</td><td>2.7</td><td>5.1</td><td>1.9</td><td>virginica</td></tr><tr><th>3</th><td>6.6</td><td>2.9</td><td>4.6</td><td>1.3</td><td>versicolor</td></tr><tr><th>4</th><td>6.3</td><td>2.5</td><td>5.0</td><td>1.9</td><td>virginica</td></tr><tr><th>5</th><td>5.0</td><td>2.0</td><td>3.5</td><td>1.0</td><td>versicolor</td></tr><tr><th>6</th><td>5.8</td><td>4.0</td><td>1.2</td><td>0.2</td><td>setosa</td></tr><tr><th>7</th><td>6.7</td><td>3.1</td><td>4.7</td><td>1.5</td><td>versicolor</td></tr><tr><th>8</th><td>5.7</td><td>2.8</td><td>4.5</td><td>1.3</td><td>versicolor</td></tr><tr><th>9</th><td>6.3</td><td>2.9</td><td>5.6</td><td>1.8</td><td>virginica</td></tr><tr><th>10</th><td>5.6</td><td>3.0</td><td>4.1</td><td>1.3</td><td>versicolor</td></tr><tr><th>11</th><td>5.6</td><td>2.7</td><td>4.2</td><td>1.3</td><td>versicolor</td></tr><tr><th>12</th><td>5.1</td><td>3.4</td><td>1.5</td><td>0.2</td><td>setosa</td></tr><tr><th>13</th><td>6.7</td><td>3.3</td><td>5.7</td><td>2.1</td><td>virginica</td></tr><tr><th>14</th><td>5.8</td><td>2.6</td><td>4.0</td><td>1.2</td><td>versicolor</td></tr><tr><th>15</th><td>6.4</td><td>2.9</td><td>4.3</td><td>1.3</td><td>versicolor</td></tr><tr><th>16</th><td>4.8</td><td>3.0</td><td>1.4</td><td>0.1</td><td>setosa</td></tr><tr><th>17</th><td>6.3</td><td>3.4</td><td>5.6</td><td>2.4</td><td>virginica</td></tr><tr><th>18</th><td>4.9</td><td>2.5</td><td>4.5</td><td>1.7</td><td>virginica</td></tr><tr><th>19</th><td>4.8</td><td>3.4</td><td>1.6</td><td>0.2</td><td>setosa</td></tr><tr><th>20</th><td>5.0</td><td>2.3</td><td>3.3</td><td>1.0</td><td>versicolor</td></tr></tbody></table><p>In this data set, the outcome <code class="language-plaintext highlighter-rouge">Species</code> is currently coded as a string. We need to convert the <code class="language-plaintext highlighter-rouge">Species</code> into 1s and 0s.</p><p>We will create three new columns: <code class="language-plaintext highlighter-rouge">Species_setosa</code>, <code class="language-plaintext highlighter-rouge">Species_versicolor</code> and <code class="language-plaintext highlighter-rouge">Species_virginica</code>.</p><ul><li>If a row has <code class="language-plaintext highlighter-rouge">setosa</code> as the species, then it will have <code class="language-plaintext highlighter-rouge">Species_setosa = 1</code>, <code class="language-plaintext highlighter-rouge">Species_versicolor = 0</code>, and <code class="language-plaintext highlighter-rouge">Species_virginica = 0</code>.</li><li>If a row has <code class="language-plaintext highlighter-rouge">versicolor</code> as the species, then it will have <code class="language-plaintext highlighter-rouge">Species_setosa = 0</code>, <code class="language-plaintext highlighter-rouge">Species_versicolor = 1</code>, and <code class="language-plaintext highlighter-rouge">Species_virginica = 0</code>.</li><li>If a row has <code class="language-plaintext highlighter-rouge">virginica</code> as the species, then it will have <code class="language-plaintext highlighter-rouge">Species_setosa = 0</code>, <code class="language-plaintext highlighter-rouge">Species_versicolor = 0</code>, and <code class="language-plaintext highlighter-rouge">Species_virginica = 1</code>.</li></ul><div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Recode the `Species` column</span><span class="n">data</span><span class="x">[</span><span class="o">!</span><span class="x">,</span><span class="o">:</span><span class="n">Species_setosa</span><span class="x">]</span><span class="o">=</span><span class="x">[</span><span class="n">r</span><span class="o">.</span><span class="n">Species</span><span class="o">==</span><span class="s">"setosa"</span><span class="o">?</span><span class="mf">1.0</span><span class="o">:</span><span class="mf">0.0</span><span class="k">for</span><span class="n">r</span><span class="k">in</span><span class="n">eachrow</span><span class="x">(</span><span class="n">data</span><span class="x">)]</span><span class="n">data</span><span class="x">[</span><span class="o">!</span><span class="x">,</span><span class="o">:</span><span class="n">Species_versicolor</span><span class="x">]</span><span class="o">=</span><span class="x">[</span><span class="n">r</span><span class="o">.</span><span class="n">Species</span><span class="o">==</span><span class="s">"versicolor"</span><span class="o">?</span><span class="mf">1.0</span><span class="o">:</span><span class="mf">0.0</span><span class="k">for</span><span class="n">r</span><span class="k">in</span><span class="n">eachrow</span><span class="x">(</span><span class="n">data</span><span class="x">)]</span><span class="n">data</span><span class="x">[</span><span class="o">!</span><span class="x">,</span><span class="o">:</span><span class="n">Species_virginica</span><span class="x">]</span><span class="o">=</span><span class="x">[</span><span class="n">r</span><span class="o">.</span><span class="n">Species</span><span class="o">==</span><span class="s">"virginica"</span><span class="o">?</span><span class="mf">1.0</span><span class="o">:</span><span class="mf">0.0</span><span class="k">for</span><span class="n">r</span><span class="k">in</span><span class="n">eachrow</span><span class="x">(</span><span class="n">data</span><span class="x">)]</span><span class="c"># Show twenty rows of the new species columns</span><span class="n">first</span><span class="x">(</span><span class="n">data</span><span class="x">[</span><span class="o">!</span><span class="x">,</span><span class="x">[</span><span class="o">:</span><span class="n">Species</span><span class="x">,</span><span class="o">:</span><span class="n">Species_setosa</span><span class="x">,</span><span class="o">:</span><span class="n">Species_versicolor</span><span class="x">,</span><span class="o">:</span><span class="n">Species_virginica</span><span class="x">]],</span><span class="mi">20</span><span class="x">)</span></code></pre></div></div><p>20 rows √ó 4 columns</p><table class="data-frame"><thead><tr><th></th><th>Species</th><th>Species_setosa</th><th>Species_versicolor</th><th>Species_virginica</th></tr><tr><th></th><th>Categorical‚Ä¶</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><tr><th>1</th><td>virginica</td><td>0.0</td><td>0.0</td><td>1.0</td></tr><tr><th>2</th><td>virginica</td><td>0.0</td><td>0.0</td><td>1.0</td></tr><tr><th>3</th><td>versicolor</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><th>4</th><td>virginica</td><td>0.0</td><td>0.0</td><td>1.0</td></tr><tr><th>5</th><td>versicolor</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><th>6</th><td>setosa</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>7</th><td>versicolor</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><th>8</th><td>versicolor</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><th>9</th><td>virginica</td><td>0.0</td><td>0.0</td><td>1.0</td></tr><tr><th>10</th><td>versicolor</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><th>11</th><td>versicolor</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><th>12</th><td>setosa</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>13</th><td>virginica</td><td>0.0</td><td>0.0</td><td>1.0</td></tr><tr><th>14</th><td>versicolor</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><th>15</th><td>versicolor</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><th>16</th><td>setosa</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>17</th><td>virginica</td><td>0.0</td><td>0.0</td><td>1.0</td></tr><tr><th>18</th><td>virginica</td><td>0.0</td><td>0.0</td><td>1.0</td></tr><tr><th>19</th><td>setosa</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>20</th><td>versicolor</td><td>0.0</td><td>1.0</td><td>0.0</td></tr></tbody></table><p>After we‚Äôve done that tidying, it‚Äôs time to split our dataset into training and testing sets, and separate the labels from the data. We separate our data into two halves, <code class="language-plaintext highlighter-rouge">train</code> and <code class="language-plaintext highlighter-rouge">test</code>.</p><p>We must rescale our feature variables so that they are centered around zero by subtracting each column by the mean and dividing it by the standard deviation. Without this step, Turing‚Äôs sampler will have a hard time finding a place to start searching for parameter estimates.</p><div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Function to split samples.</span><span class="k">function</span><span class="nf"> split_data</span><span class="x">(</span><span class="n">df</span><span class="x">,</span><span class="n">at</span><span class="x">)</span><span class="x">(</span><span class="n">r</span><span class="x">,</span><span class="n">_</span><span class="x">)</span><span class="o">=</span><span class="n">size</span><span class="x">(</span><span class="n">df</span><span class="x">)</span><span class="n">index</span><span class="o">=</span><span class="kt">Int</span><span class="x">(</span><span class="n">round</span><span class="x">(</span><span class="n">r</span><span class="o">*</span><span class="n">at</span><span class="x">))</span><span class="n">train</span><span class="o">=</span><span class="n">df</span><span class="x">[</span><span class="mi">1</span><span class="o">:</span><span class="n">index</span><span class="x">,</span><span class="o">:</span><span class="x">]</span><span class="n">test</span><span class="o">=</span><span class="n">df</span><span class="x">[(</span><span class="n">index</span><span class="o">+</span><span class="mi">1</span><span class="x">)</span><span class="o">:</span><span class="k">end</span><span class="x">,</span><span class="o">:</span><span class="x">]</span><span class="k">return</span><span class="n">train</span><span class="x">,</span><span class="n">test</span><span class="k">end</span><span class="c"># Rescale our feature variables.</span><span class="n">data</span><span class="o">.</span><span class="n">SepalLength</span><span class="o">=</span><span class="x">(</span><span class="n">data</span><span class="o">.</span><span class="n">SepalLength</span><span class="o">.-</span><span class="n">mean</span><span class="x">(</span><span class="n">data</span><span class="o">.</span><span class="n">SepalLength</span><span class="x">))</span><span class="o">./</span><span class="n">std</span><span class="x">(</span><span class="n">data</span><span class="o">.</span><span class="n">SepalLength</span><span class="x">)</span><span class="n">data</span><span class="o">.</span><span class="n">SepalWidth</span><span class="o">=</span><span class="x">(</span><span class="n">data</span><span class="o">.</span><span class="n">SepalWidth</span><span class="o">.-</span><span class="n">mean</span><span class="x">(</span><span class="n">data</span><span class="o">.</span><span class="n">SepalWidth</span><span class="x">))</span><span class="o">./</span><span class="n">std</span><span class="x">(</span><span class="n">data</span><span class="o">.</span><span class="n">SepalWidth</span><span class="x">)</span><span class="n">data</span><span class="o">.</span><span class="n">PetalLength</span><span class="o">=</span><span class="x">(</span><span class="n">data</span><span class="o">.</span><span class="n">PetalLength</span><span class="o">.-</span><span class="n">mean</span><span class="x">(</span><span class="n">data</span><span class="o">.</span><span class="n">PetalLength</span><span class="x">))</span><span class="o">./</span><span class="n">std</span><span class="x">(</span><span class="n">data</span><span class="o">.</span><span class="n">PetalLength</span><span class="x">)</span><span class="n">data</span><span class="o">.</span><span class="n">PetalWidth</span><span class="o">=</span><span class="x">(</span><span class="n">data</span><span class="o">.</span><span class="n">PetalWidth</span><span class="o">.-</span><span class="n">mean</span><span class="x">(</span><span class="n">data</span><span class="o">.</span><span class="n">PetalWidth</span><span class="x">))</span><span class="o">./</span><span class="n">std</span><span class="x">(</span><span class="n">data</span><span class="o">.</span><span class="n">PetalWidth</span><span class="x">)</span><span class="c"># Split our dataset 50/50 into training/test sets.</span><span class="n">train</span><span class="x">,</span><span class="n">test</span><span class="o">=</span><span class="n">split_data</span><span class="x">(</span><span class="n">data</span><span class="x">,</span><span class="mf">0.50</span><span class="x">);</span><span class="n">label_names</span><span class="o">=</span><span class="x">[</span><span class="o">:</span><span class="n">Species_setosa</span><span class="x">,</span><span class="o">:</span><span class="n">Species_versicolor</span><span class="x">,</span><span class="o">:</span><span class="n">Species_virginica</span><span class="x">]</span><span class="n">feature_names</span><span class="o">=</span><span class="x">[</span><span class="o">:</span><span class="n">SepalLength</span><span class="x">,</span><span class="o">:</span><span class="n">SepalWidth</span><span class="x">,</span><span class="o">:</span><span class="n">PetalLength</span><span class="x">,</span><span class="o">:</span><span class="n">PetalWidth</span><span class="x">]</span><span class="c"># Create our labels. These are the values we are trying to predict.</span><span class="n">train_labels</span><span class="o">=</span><span class="n">train</span><span class="x">[</span><span class="o">:</span><span class="x">,</span><span class="n">label_names</span><span class="x">]</span><span class="n">test_labels</span><span class="o">=</span><span class="n">test</span><span class="x">[</span><span class="o">:</span><span class="x">,</span><span class="n">label_names</span><span class="x">]</span><span class="c"># Create our features. These are our predictors.</span><span class="n">train_features</span><span class="o">=</span><span class="n">train</span><span class="x">[</span><span class="o">:</span><span class="x">,</span><span class="n">feature_names</span><span class="x">];</span><span class="n">test_features</span><span class="o">=</span><span class="n">test</span><span class="x">[</span><span class="o">:</span><span class="x">,</span><span class="n">feature_names</span><span class="x">];</span></code></pre></div></div><p>Our <code class="language-plaintext highlighter-rouge">train</code> and <code class="language-plaintext highlighter-rouge">test</code> matrices are still in the <code class="language-plaintext highlighter-rouge">DataFrame</code> format, which tends not to play too well with the kind of manipulations we‚Äôre about to do, so we convert them into <code class="language-plaintext highlighter-rouge">Matrix</code> objects.</p><div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Convert the DataFrame objects to matrices.</span><span class="n">train_labels</span><span class="o">=</span><span class="kt">Matrix</span><span class="x">(</span><span class="n">train_labels</span><span class="x">);</span><span class="n">test_labels</span><span class="o">=</span><span class="kt">Matrix</span><span class="x">(</span><span class="n">test_labels</span><span class="x">);</span><span class="n">train_features</span><span class="o">=</span><span class="kt">Matrix</span><span class="x">(</span><span class="n">train_features</span><span class="x">);</span><span class="n">test_features</span><span class="o">=</span><span class="kt">Matrix</span><span class="x">(</span><span class="n">test_features</span><span class="x">);</span></code></pre></div></div><h2 id="model-declaration">Model Declaration</h2><p>Finally, we can define our model.</p><p><code class="language-plaintext highlighter-rouge">logistic_regression</code> takes four arguments:</p><ul><li><code class="language-plaintext highlighter-rouge">x</code> is our set of independent variables;</li><li><code class="language-plaintext highlighter-rouge">y</code> is the element we want to predict;</li><li><code class="language-plaintext highlighter-rouge">n</code> is the number of observations we have; and</li><li><code class="language-plaintext highlighter-rouge">œÉ</code> is the standard deviation we want to assume for our priors.</li></ul><p>We need to create our coefficients. To do so, we first need to select one of the species as the baseline species. The selection of the baseline class does not matter. Then we create our coefficients against that baseline.</p><p>Let us select <code class="language-plaintext highlighter-rouge">"setosa"</code> as the baseline. We create ten coefficients (<code class="language-plaintext highlighter-rouge">intercept_versicolor</code>, <code class="language-plaintext highlighter-rouge">intercept_virginica</code>, <code class="language-plaintext highlighter-rouge">SepalLength_versicolor</code>, <code class="language-plaintext highlighter-rouge">SepalLength_virginica</code>, <code class="language-plaintext highlighter-rouge">SepalWidth_versicolor</code>, <code class="language-plaintext highlighter-rouge">SepalWidth_virginica</code>, <code class="language-plaintext highlighter-rouge">PetalLength_versicolor</code>, <code class="language-plaintext highlighter-rouge">PetalLength_virginica</code>, <code class="language-plaintext highlighter-rouge">PetalWidth_versicolor</code>, and <code class="language-plaintext highlighter-rouge">PetalWidth_virginica</code>) and assign a prior of normally distributed with means of zero and standard deviations of <code class="language-plaintext highlighter-rouge">œÉ</code>. We want to find values of these ten coefficients to predict any given <code class="language-plaintext highlighter-rouge">y</code>.</p><p>The <code class="language-plaintext highlighter-rouge">for</code> block creates a variable <code class="language-plaintext highlighter-rouge">v</code> which is the softmax function. We then observe the liklihood of calculating <code class="language-plaintext highlighter-rouge">v</code> given the actual label, <code class="language-plaintext highlighter-rouge">y[i]</code>.</p><div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Bayesian multinomial logistic regression</span><span class="nd">@model</span><span class="n">logistic_regression</span><span class="x">(</span><span class="n">x</span><span class="x">,</span><span class="n">y</span><span class="x">,</span><span class="n">n</span><span class="x">,</span><span class="n">œÉ</span><span class="x">)</span><span class="o">=</span><span class="k">begin</span><span class="n">intercept_versicolor</span><span class="o">~</span><span class="n">Normal</span><span class="x">(</span><span class="mi">0</span><span class="x">,</span><span class="n">œÉ</span><span class="x">)</span><span class="n">intercept_virginica</span><span class="o">~</span><span class="n">Normal</span><span class="x">(</span><span class="mi">0</span><span class="x">,</span><span class="n">œÉ</span><span class="x">)</span><span class="n">SepalLength_versicolor</span><span class="o">~</span><span class="n">Normal</span><span class="x">(</span><span class="mi">0</span><span class="x">,</span><span class="n">œÉ</span><span class="x">)</span><span class="n">SepalLength_virginica</span><span class="o">~</span><span class="n">Normal</span><span class="x">(</span><span class="mi">0</span><span class="x">,</span><span class="n">œÉ</span><span class="x">)</span><span class="n">SepalWidth_versicolor</span><span class="o">~</span><span class="n">Normal</span><span class="x">(</span><span class="mi">0</span><span class="x">,</span><span class="n">œÉ</span><span class="x">)</span><span class="n">SepalWidth_virginica</span><span class="o">~</span><span class="n">Normal</span><span class="x">(</span><span class="mi">0</span><span class="x">,</span><span class="n">œÉ</span><span class="x">)</span><span class="n">PetalLength_versicolor</span><span class="o">~</span><span class="n">Normal</span><span class="x">(</span><span class="mi">0</span><span class="x">,</span><span class="n">œÉ</span><span class="x">)</span><span class="n">PetalLength_virginica</span><span class="o">~</span><span class="n">Normal</span><span class="x">(</span><span class="mi">0</span><span class="x">,</span><span class="n">œÉ</span><span class="x">)</span><span class="n">PetalWidth_versicolor</span><span class="o">~</span><span class="n">Normal</span><span class="x">(</span><span class="mi">0</span><span class="x">,</span><span class="n">œÉ</span><span class="x">)</span><span class="n">PetalWidth_virginica</span><span class="o">~</span><span class="n">Normal</span><span class="x">(</span><span class="mi">0</span><span class="x">,</span><span class="n">œÉ</span><span class="x">)</span><span class="k">for</span><span class="n">i</span><span class="o">=</span><span class="mi">1</span><span class="o">:</span><span class="n">n</span><span class="n">v</span><span class="o">=</span><span class="n">softmax</span><span class="x">([</span><span class="mi">0</span><span class="x">,</span><span class="c"># this 0 corresponds to the base category `setosa`</span><span class="n">intercept_versicolor</span><span class="o">+</span><span class="n">SepalLength_versicolor</span><span class="o">*</span><span class="n">x</span><span class="x">[</span><span class="n">i</span><span class="x">,</span><span class="mi">1</span><span class="x">]</span><span class="o">+</span><span class="n">SepalWidth_versicolor</span><span class="o">*</span><span class="n">x</span><span class="x">[</span><span class="n">i</span><span class="x">,</span><span class="mi">1</span><span class="x">]</span><span class="o">+</span><span class="n">PetalLength_versicolor</span><span class="o">*</span><span class="n">x</span><span class="x">[</span><span class="n">i</span><span class="x">,</span><span class="mi">2</span><span class="x">]</span><span class="o">+</span><span class="n">PetalWidth_versicolor</span><span class="o">*</span><span class="n">x</span><span class="x">[</span><span class="n">i</span><span class="x">,</span><span class="mi">2</span><span class="x">],</span><span class="n">intercept_virginica</span><span class="o">+</span><span class="n">SepalLength_virginica</span><span class="o">*</span><span class="n">x</span><span class="x">[</span><span class="n">i</span><span class="x">,</span><span class="mi">3</span><span class="x">]</span><span class="o">+</span><span class="n">SepalWidth_virginica</span><span class="o">*</span><span class="n">x</span><span class="x">[</span><span class="n">i</span><span class="x">,</span><span class="mi">3</span><span class="x">]</span><span class="o">+</span><span class="n">PetalLength_virginica</span><span class="o">*</span><span class="n">x</span><span class="x">[</span><span class="n">i</span><span class="x">,</span><span class="mi">4</span><span class="x">]</span><span class="o">+</span><span class="n">PetalWidth_virginica</span><span class="o">*</span><span class="n">x</span><span class="x">[</span><span class="n">i</span><span class="x">,</span><span class="mi">4</span><span class="x">]])</span><span class="n">y</span><span class="x">[</span><span class="n">i</span><span class="x">,</span><span class="o">:</span><span class="x">]</span><span class="o">~</span><span class="n">Multinomial</span><span class="x">(</span><span class="mi">1</span><span class="x">,</span><span class="n">v</span><span class="x">)</span><span class="k">end</span><span class="k">end</span><span class="x">;</span></code></pre></div></div><h2 id="sampling">Sampling</h2><p>Now we can run our sampler. This time we‚Äôll use <a href="http://turing.ml/docs/library/#Turing.HMC"><code class="language-plaintext highlighter-rouge">HMC</code></a> to sample from our posterior.</p><div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Retrieve the number of observations.</span><span class="n">n</span><span class="x">,</span><span class="n">_</span><span class="o">=</span><span class="n">size</span><span class="x">(</span><span class="n">train_features</span><span class="x">)</span><span class="c"># Sample using HMC.</span><span class="n">chain</span><span class="o">=</span><span class="n">mapreduce</span><span class="x">(</span><span class="n">c</span><span class="o">-&gt;</span><span class="n">sample</span><span class="x">(</span><span class="n">logistic_regression</span><span class="x">(</span><span class="n">train_features</span><span class="x">,</span><span class="n">train_labels</span><span class="x">,</span><span class="n">n</span><span class="x">,</span><span class="mi">1</span><span class="x">),</span><span class="n">HMC</span><span class="x">(</span><span class="mf">0.05</span><span class="x">,</span><span class="mi">10</span><span class="x">),</span><span class="mi">1500</span><span class="x">),</span><span class="n">chainscat</span><span class="x">,</span><span class="mi">1</span><span class="o">:</span><span class="mi">3</span><span class="x">)</span><span class="n">describe</span><span class="x">(</span><span class="n">chain</span><span class="x">)</span></code></pre></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ÔøΩ[32mSampling: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Time: 0:00:05ÔøΩ[39m
ÔøΩ[32mSampling: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Time: 0:00:04ÔøΩ[39m
ÔøΩ[32mSampling: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Time: 0:00:04ÔøΩ[39m





2-element Array{ChainDataFrame,1}

Summary Statistics
              parameters     mean     std  naive_se    mcse        ess   r_hat
  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  PetalLength_versicolor  -0.7982  0.7341    0.0109  0.0353   330.7338  1.0022
   PetalLength_virginica   1.7376  0.8532    0.0127  0.0424   415.6667  1.0023
   PetalWidth_versicolor  -0.7018  0.7335    0.0109  0.0339   355.4789  1.0017
    PetalWidth_virginica   1.6843  0.8452    0.0126  0.0382   447.2635  1.0089
  SepalLength_versicolor   0.8642  0.7315    0.0109  0.0357   370.1195  1.0052
   SepalLength_virginica   1.5303  0.8641    0.0129  0.0452   321.9949  1.0078
   SepalWidth_versicolor   0.8227  0.7506    0.0112  0.0363   364.8514  1.0036
    SepalWidth_virginica   1.5765  0.8516    0.0127  0.0468   405.3356  1.0078
    intercept_versicolor   1.0275  0.4539    0.0068  0.0156  1004.6000  1.0029
     intercept_virginica  -0.9449  0.6155    0.0092  0.0246   700.5740  1.0033

Quantiles
              parameters     2.5%    25.0%    50.0%    75.0%   97.5%
  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  PetalLength_versicolor  -2.2429  -1.2926  -0.7839  -0.2936  0.5790
   PetalLength_virginica   0.0566   1.1492   1.7495   2.3157  3.4072
   PetalWidth_versicolor  -2.1443  -1.2000  -0.7049  -0.2173  0.7632
    PetalWidth_virginica  -0.0565   1.1274   1.6940   2.2695  3.2582
  SepalLength_versicolor  -0.5667   0.3953   0.8762   1.3547  2.2408
   SepalLength_virginica  -0.1067   0.9405   1.5259   2.0997  3.2549
   SepalWidth_versicolor  -0.5795   0.3072   0.8086   1.3063  2.3417
    SepalWidth_virginica  -0.1364   1.0034   1.5684   2.1657  3.2340
    intercept_versicolor   0.1491   0.7267   1.0235   1.3287  1.9327
     intercept_virginica  -2.1602  -1.3516  -0.9434  -0.5233  0.2201
</code></pre></div></div><p>Since we ran multiple chains, we may as well do a spot check to make sure each chain converges around similar points.</p><div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plot</span><span class="x">(</span><span class="n">chain</span><span class="x">)</span></code></pre></div></div><p><img alt="svg" src="../8_MultinomialLogisticRegression_files/8_MultinomialLogisticRegression_15_0.svg"/></p><p>Looks good!</p><p>We can also use the <code class="language-plaintext highlighter-rouge">corner</code> function from MCMCChains to show the distributions of the various parameters of our multinomial logistic regression. The corner function requires MCMCChains and StatsPlots.</p><div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">corner</span><span class="x">(</span><span class="n">chain</span><span class="x">,</span><span class="x">[</span><span class="o">:</span><span class="n">SepalLength_versicolor</span><span class="x">,</span><span class="o">:</span><span class="n">SepalWidth_versicolor</span><span class="x">,</span><span class="o">:</span><span class="n">PetalLength_versicolor</span><span class="x">,</span><span class="o">:</span><span class="n">PetalWidth_versicolor</span><span class="x">])</span></code></pre></div></div><p><img alt="svg" src="../8_MultinomialLogisticRegression_files/8_MultinomialLogisticRegression_17_0.svg"/></p><div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">corner</span><span class="x">(</span><span class="n">chain</span><span class="x">,</span><span class="x">[</span><span class="o">:</span><span class="n">SepalLength_versicolor</span><span class="x">,</span><span class="o">:</span><span class="n">SepalWidth_versicolor</span><span class="x">,</span><span class="o">:</span><span class="n">PetalLength_versicolor</span><span class="x">,</span><span class="o">:</span><span class="n">PetalWidth_versicolor</span><span class="x">])</span></code></pre></div></div><p><img alt="svg" src="../8_MultinomialLogisticRegression_files/8_MultinomialLogisticRegression_18_0.svg"/></p><p>Fortunately the corner plots appear to demonstrate unimodal distributions for each of our parameters, so it should be straightforward to take the means of each parameter‚Äôs sampled values to estimate our model to make predictions.</p><h2 id="making-predictions">Making Predictions</h2><p>How do we test how well the model actually predicts whether someone is likely to default? We need to build a prediction function that takes the <code class="language-plaintext highlighter-rouge">test</code> object we made earlier and runs it through the average parameter calculated during sampling.</p><p>The <code class="language-plaintext highlighter-rouge">prediction</code> function below takes a <code class="language-plaintext highlighter-rouge">Matrix</code> and a <code class="language-plaintext highlighter-rouge">Chain</code> object. It takes the mean of each parameter‚Äôs sampled values and re-runs the softmax function using those mean values for every element in the test set.</p><div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">function</span><span class="nf"> prediction</span><span class="x">(</span><span class="n">x</span><span class="o">::</span><span class="kt">Matrix</span><span class="x">,</span><span class="n">chain</span><span class="x">)</span><span class="c"># Pull the means from each parameter's sampled values in the chain.</span><span class="n">intercept_versicolor</span><span class="o">=</span><span class="n">mean</span><span class="x">(</span><span class="n">chain</span><span class="x">[</span><span class="o">:</span><span class="n">intercept_versicolor</span><span class="x">]</span><span class="o">.</span><span class="n">value</span><span class="x">)</span><span class="n">intercept_virginica</span><span class="o">=</span><span class="n">mean</span><span class="x">(</span><span class="n">chain</span><span class="x">[</span><span class="o">:</span><span class="n">intercept_virginica</span><span class="x">]</span><span class="o">.</span><span class="n">value</span><span class="x">)</span><span class="n">SepalLength_versicolor</span><span class="o">=</span><span class="n">mean</span><span class="x">(</span><span class="n">chain</span><span class="x">[</span><span class="o">:</span><span class="n">SepalLength_versicolor</span><span class="x">]</span><span class="o">.</span><span class="n">value</span><span class="x">)</span><span class="n">SepalLength_virginica</span><span class="o">=</span><span class="n">mean</span><span class="x">(</span><span class="n">chain</span><span class="x">[</span><span class="o">:</span><span class="n">SepalLength_virginica</span><span class="x">]</span><span class="o">.</span><span class="n">value</span><span class="x">)</span><span class="n">SepalWidth_versicolor</span><span class="o">=</span><span class="n">mean</span><span class="x">(</span><span class="n">chain</span><span class="x">[</span><span class="o">:</span><span class="n">SepalWidth_versicolor</span><span class="x">]</span><span class="o">.</span><span class="n">value</span><span class="x">)</span><span class="n">SepalWidth_virginica</span><span class="o">=</span><span class="n">mean</span><span class="x">(</span><span class="n">chain</span><span class="x">[</span><span class="o">:</span><span class="n">SepalWidth_virginica</span><span class="x">]</span><span class="o">.</span><span class="n">value</span><span class="x">)</span><span class="n">PetalLength_versicolor</span><span class="o">=</span><span class="n">mean</span><span class="x">(</span><span class="n">chain</span><span class="x">[</span><span class="o">:</span><span class="n">PetalLength_versicolor</span><span class="x">]</span><span class="o">.</span><span class="n">value</span><span class="x">)</span><span class="n">PetalLength_virginica</span><span class="o">=</span><span class="n">mean</span><span class="x">(</span><span class="n">chain</span><span class="x">[</span><span class="o">:</span><span class="n">PetalLength_virginica</span><span class="x">]</span><span class="o">.</span><span class="n">value</span><span class="x">)</span><span class="n">PetalWidth_versicolor</span><span class="o">=</span><span class="n">mean</span><span class="x">(</span><span class="n">chain</span><span class="x">[</span><span class="o">:</span><span class="n">PetalWidth_versicolor</span><span class="x">]</span><span class="o">.</span><span class="n">value</span><span class="x">)</span><span class="n">PetalWidth_virginica</span><span class="o">=</span><span class="n">mean</span><span class="x">(</span><span class="n">chain</span><span class="x">[</span><span class="o">:</span><span class="n">PetalWidth_virginica</span><span class="x">]</span><span class="o">.</span><span class="n">value</span><span class="x">)</span><span class="c"># Retrieve the number of rows.</span><span class="n">n</span><span class="x">,</span><span class="n">_</span><span class="o">=</span><span class="n">size</span><span class="x">(</span><span class="n">x</span><span class="x">)</span><span class="c"># Generate a vector to store our predictions.</span><span class="n">v</span><span class="o">=</span><span class="kt">Vector</span><span class="x">{</span><span class="kt">String</span><span class="x">}(</span><span class="nb">undef</span><span class="x">,</span><span class="n">n</span><span class="x">)</span><span class="c"># Calculate the softmax function for each element in the test set.</span><span class="k">for</span><span class="n">i</span><span class="k">in</span><span class="mi">1</span><span class="o">:</span><span class="n">n</span><span class="n">num</span><span class="o">=</span><span class="n">softmax</span><span class="x">([</span><span class="mi">0</span><span class="x">,</span><span class="c"># this 0 corresponds to the base category `setosa`</span><span class="n">intercept_versicolor</span><span class="o">+</span><span class="n">SepalLength_versicolor</span><span class="o">*</span><span class="n">x</span><span class="x">[</span><span class="n">i</span><span class="x">,</span><span class="mi">1</span><span class="x">]</span><span class="o">+</span><span class="n">SepalWidth_versicolor</span><span class="o">*</span><span class="n">x</span><span class="x">[</span><span class="n">i</span><span class="x">,</span><span class="mi">1</span><span class="x">]</span><span class="o">+</span><span class="n">PetalLength_versicolor</span><span class="o">*</span><span class="n">x</span><span class="x">[</span><span class="n">i</span><span class="x">,</span><span class="mi">2</span><span class="x">]</span><span class="o">+</span><span class="n">PetalWidth_versicolor</span><span class="o">*</span><span class="n">x</span><span class="x">[</span><span class="n">i</span><span class="x">,</span><span class="mi">2</span><span class="x">],</span><span class="n">intercept_virginica</span><span class="o">+</span><span class="n">SepalLength_virginica</span><span class="o">*</span><span class="n">x</span><span class="x">[</span><span class="n">i</span><span class="x">,</span><span class="mi">3</span><span class="x">]</span><span class="o">+</span><span class="n">SepalWidth_virginica</span><span class="o">*</span><span class="n">x</span><span class="x">[</span><span class="n">i</span><span class="x">,</span><span class="mi">3</span><span class="x">]</span><span class="o">+</span><span class="n">PetalLength_virginica</span><span class="o">*</span><span class="n">x</span><span class="x">[</span><span class="n">i</span><span class="x">,</span><span class="mi">4</span><span class="x">]</span><span class="o">+</span><span class="n">PetalWidth_virginica</span><span class="o">*</span><span class="n">x</span><span class="x">[</span><span class="n">i</span><span class="x">,</span><span class="mi">4</span><span class="x">]])</span><span class="n">c</span><span class="o">=</span><span class="n">argmax</span><span class="x">(</span><span class="n">num</span><span class="x">)</span><span class="c"># we pick the class with the highest probability</span><span class="k">if</span><span class="n">c</span><span class="o">==</span><span class="mi">1</span><span class="n">v</span><span class="x">[</span><span class="n">i</span><span class="x">]</span><span class="o">=</span><span class="s">"setosa"</span><span class="k">elseif</span><span class="n">c</span><span class="o">==</span><span class="mi">2</span><span class="n">v</span><span class="x">[</span><span class="n">i</span><span class="x">]</span><span class="o">=</span><span class="s">"versicolor"</span><span class="k">else</span><span class="c"># c == 3</span><span class="nd">@assert</span><span class="n">c</span><span class="o">==</span><span class="mi">3</span><span class="n">v</span><span class="x">[</span><span class="n">i</span><span class="x">]</span><span class="o">=</span><span class="s">"virginica"</span><span class="k">end</span><span class="k">end</span><span class="k">return</span><span class="n">v</span><span class="k">end</span><span class="x">;</span></code></pre></div></div><p>Let‚Äôs see how we did! We run the test matrix through the prediction function, and compute the accuracy for our prediction.</p><div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Make the predictions.</span><span class="n">predictions</span><span class="o">=</span><span class="n">prediction</span><span class="x">(</span><span class="n">test_features</span><span class="x">,</span><span class="n">chain</span><span class="x">)</span><span class="c"># Calculate accuracy for our test set.</span><span class="n">mean</span><span class="x">(</span><span class="n">predictions</span><span class="o">.==</span><span class="n">test</span><span class="x">[</span><span class="o">!</span><span class="x">,</span><span class="o">:</span><span class="n">Species</span><span class="x">])</span></code></pre></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0.8933333333333333
</code></pre></div></div><p>Perhaps more important is to see the accuracy per class.</p><div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">setosa_rows</span><span class="o">=</span><span class="n">test</span><span class="x">[</span><span class="o">!</span><span class="x">,</span><span class="o">:</span><span class="n">Species</span><span class="x">]</span><span class="o">.==</span><span class="s">"setosa"</span><span class="n">versicolor_rows</span><span class="o">=</span><span class="n">test</span><span class="x">[</span><span class="o">!</span><span class="x">,</span><span class="o">:</span><span class="n">Species</span><span class="x">]</span><span class="o">.==</span><span class="s">"versicolor"</span><span class="n">virginica_rows</span><span class="o">=</span><span class="n">test</span><span class="x">[</span><span class="o">!</span><span class="x">,</span><span class="o">:</span><span class="n">Species</span><span class="x">]</span><span class="o">.==</span><span class="s">"virginica"</span><span class="n">println</span><span class="x">(</span><span class="s">"Number of setosa: </span><span class="si">$$</span><span class="s">(sum(setosa_rows))"</span><span class="x">)</span><span class="n">println</span><span class="x">(</span><span class="s">"Number of versicolor: </span><span class="si">$$</span><span class="s">(sum(versicolor_rows))"</span><span class="x">)</span><span class="n">println</span><span class="x">(</span><span class="s">"Number of virginica: </span><span class="si">$$</span><span class="s">(sum(virginica_rows))"</span><span class="x">)</span><span class="n">println</span><span class="x">(</span><span class="s">"Percentage of setosa predicted correctly: </span><span class="si">$$</span><span class="s">(mean(predictions[setosa_rows] .== test[setosa_rows, :Species]))"</span><span class="x">)</span><span class="n">println</span><span class="x">(</span><span class="s">"Percentage of versicolor predicted correctly: </span><span class="si">$$</span><span class="s">(mean(predictions[versicolor_rows] .== test[versicolor_rows, :Species]))"</span><span class="x">)</span><span class="n">println</span><span class="x">(</span><span class="s">"Percentage of virginica predicted correctly: </span><span class="si">$$</span><span class="s">(mean(predictions[virginica_rows] .== test[virginica_rows, :Species]))"</span><span class="x">)</span></code></pre></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Number of setosa: 32
Number of versicolor: 25
Number of virginica: 18
Percentage of setosa predicted correctly: 0.96875
Percentage of versicolor predicted correctly: 0.76
Percentage of virginica predicted correctly: 0.9444444444444444
</code></pre></div></div><p>This tutorial has demonstrated how to use Turing to perform Bayesian multinomial logistic regression.</p><script crossorigin="anonymous" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" src="https://code.jquery.com/jquery-3.3.1.min.js"></script><script>
$(document).ready(function() {

    var toc = $('#nav-toc');

    // Select each header
    sections = $('#md-container-pancakes h1');
        $.each(sections, function(idx, v) {
            section = $(v);
            var div_id = $(section).attr('id');
            var div_text = section.text().split('¬∂')[0];
            var parent = $("#" + div_id)
            var content = '<li id="link_' + div_id + '" class="md-nav__item"><a class="md-nav__link toc-side-bar" href="#' + div_id + '" title="' + div_text +'">' + div_text +'</a></li>';
            $(toc).append(content);

            // Add section code to subnavigation
            var children = $('<nav class="md-nav"><ul class="md-nav__list"></nav></ul>')
            var contenders = $("#" + div_id).nextUntil( "h1" );
            $.each(contenders, function(idx, contender){
            if($(contender).is('h2')) {
                var contender_id = $(contender).attr('id');
                var contender_text = $(contender).text().split('¬∂')[0];
                var content = '<li class="md-nav__item"><a class="md-nav__link toc-side-bar" href="#' + contender_id + '" title="' + contender_text +'">' + contender_text +'</a></li>';
                children.append(content);
                }
            })
            $("#link_" + div_id).append(children);
        });
    });
</script><style>
.more {
    float:right;
    font-size: 1.0rem !important;
}
.more:hover {
    color: cornflowerblue !important;
}

.dropdown {
    position: relative;
    display: inline-block;
}

.dropdown-content {
    display: none;
    position: absolute;
    background-color: #f9f9f9;
    min-width: 160px;
    font-weight: 200;
    box-shadow: 0px 8px 6px 0px rgba(0,0,0,0.2);
    padding: 0px 10px;
    z-index: 1;
}

.dropdown:hover .dropdown-content {
    display: block;
}
</style></article></div></div></div></main></div><footer class="c-footer md-footer-nav"><div class="md-footer-copyright__highlight">
    
    Turing is created by <a href="http://mlg.eng.cam.ac.uk/hong/" style="color:inherit; text-decoration: underline;">Hong Ge</a>, 
    and lovingly maintained by the <a href="https://github.com/TuringLang/Turing.jl/graphs/contributors" style="color:inherit; text-decoration: underline;">core team</a> of volunteers.

    <br/><br/>
    
    The contents of this website are
¬© 2020 under the terms of the <a href="https://github.com/TuringLang/Turing.jl/blob/master/LICENCE" style="color:inherit; text-decoration: underline;">MIT License</a>.
    
  </div></footer><script src="/v0.14.0/assets/js/application.js"></script><script>console.log('3')</script><script>app.initialize({version:"0.17.4", url:{base:'/v0.14.0'}})</script><script src="/v0.14.0/assets/js/version-switch.js"></script><script>
var headers = ["h1", "h2", "h3", "h4"]
var colors = ["red", "orange", "green", "blue"]

$.each(headers, function(i, header){
    var color = colors[i];
    $(header).each(function () {
        var href=$(this).attr("id");
        $(this).append('<a class="headerlink" style="color:' + color + '" href="#' + href + '" title="Permanent link">¬∂</a>')
    });
})

// Ensure that sidebar on left has arrows
$(".pancakes-parent").on('click', function(){
    console.log($(this).next());
    $(this).next().find('.pancakes-child').toggle();
    if ($(this).hasClass('open-parent')){
        $(this).removeClass('open-parent');
    } else {
        $(this).addClass('open-parent');
    }
})

$(".pancakes-parent-mobile").on('click', function(){
    var nav = $(this).next();
     nav.addClass('mobile-sub-navbar-display');
})

$(".mobile-navbar-back").on('click', function(){
    var nav = $(this).parent();
    nav.removeClass('mobile-sub-navbar-display');
})

</script><script async="" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML" type="text/javascript"></script><script>
$('h1').first().append('<div></div>')</script><style>
#scrolltop {
  display: none; /* Hidden by default */
  position: fixed; /* Fixed/sticky position */
  bottom: 20px; /* Place the button at the bottom of the page */
  right: 30px; /* Place the button 30px from the right */
  z-index: 99; /* Make sure it does not overlap */
  border: none; /* Remove borders */
  outline: none; /* Remove outline */
  background-color: #d2e6f5; /* Set a background color */
  color: white; /* Text color */
  cursor: pointer; /* Add a mouse pointer on hover */
  padding: 10px 15px; /* Some padding */
  border-radius: 100px; /* Rounded corners */
  font-size: 18px; /* Increase font size */
  font-weight: 600;
}

#scrolltop:hover {
  background-color: #555; /* Add a dark-grey background on hover */
}
</style><button id="scrolltop" onclick="topFunction()" title="Go to top">üîù</button><script>
// When the user scrolls down 20px from the top of the document, show the button
window.onscroll = function() {scrollFunction()};

function scrollFunction() {
  if (document.body.scrollTop > 20 || document.documentElement.scrollTop > 20) {
    document.getElementById("scrolltop").style.display = "block";
  } else {
    document.getElementById("scrolltop").style.display = "none";
  }
}

// When the user clicks on the button, scroll to the top of the document
function topFunction() {
  document.body.scrollTop = 0; // For Safari
  document.documentElement.scrollTop = 0; // For Chrome, Firefox, IE and Opera
}
</script></body></HTML>